{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWiZbe1c607m"
   },
   "source": [
    " In this notebook you will need to fill in some missing code to answer the questions below.\n",
    "You will need to scroll down towards the bottom of this notebook to see the instructions.\n",
    "\n",
    "Remember, with later versions of keras you must access it via 'tensorflow.keras' and not only 'keras', e.g., `from tensorflow.keras.layers import Dense`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2iVOQUNdQZAt"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(0)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(0)\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y3YlUUkIm48Q"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "H-yw-1-tQg9T"
   },
   "outputs": [],
   "source": [
    "def display_image(data, index):\n",
    "    im = data[index]\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-p55278iQpZ5"
   },
   "outputs": [],
   "source": [
    "def onehotencode(y_train, y_test):\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    \n",
    "    # One-hot encode y data\n",
    "    y_train_categorical = to_categorical(y_train)\n",
    "    y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "    return y_train_categorical, y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KYWawMfEQ5aJ"
   },
   "outputs": [],
   "source": [
    "def build_fit_eval_model(x_train, x_test, y_train_categorical, y_test_categorical):\n",
    "    # Import dependancies\n",
    "    from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    \n",
    "    height = x_train.shape[1]\n",
    "    width = x_train.shape[2]\n",
    "    channels = 3\n",
    "    num_classes = y_train_categorical.shape[1]\n",
    "    \n",
    "    # Reshape data \n",
    "    x_train_cnn = x_train.reshape(x_train.shape[0], height, width, channels)\n",
    "    x_test_cnn = x_test.reshape(x_test.shape[0], height, width, channels)\n",
    "    \n",
    "    # Build model here.\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, \n",
    "                kernel_size=(5,5), \n",
    "                padding='same', \n",
    "                activation='relu',\n",
    "                input_shape=(height, width, channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),\n",
    "                      strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile model here\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(learning_rate=0.0001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit model here\n",
    "    history = model.fit(x_train_cnn, y_train_categorical, epochs=10)\n",
    "\n",
    "    # Evaluate model on test set here\n",
    "    loss, accuracy = model.evaluate(x_test_cnn, y_test_categorical)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BGWbgJwmr767"
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, data, indices):\n",
    "    display_image(x_test, indices[0])\n",
    "    display_image(x_test, indices[1])\n",
    "\n",
    "    predictions = model.predict(data[indices])\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhukcqeR6UFg"
   },
   "source": [
    "# STEP ZERO\n",
    "You may want to consult the [notebook provided for week 4 on deep learning](https://colab.research.google.com/drive/176yS-mw-fO0JI1CAN97wgmyRx0N9xriI?usp=sharing). It has everything you need to complete the steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaQPziM0tQOh"
   },
   "source": [
    "# STEP ONE\n",
    "\n",
    "You need to fill in the code for the load_data function above. Scroll up to the load_data function and import and load the CIFAR10 dataset from Keras (https://keras.io/api/datasets/cifar10/). CIFAR10 is a dataset of 70,000 labeled images, each belonging to one of ten classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ra8zqLSenIVO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce so we will re-download the data.\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 5229s 31us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmcKru05suze"
   },
   "source": [
    "# STEP TWO\n",
    "You need to fill in the code for the display_image function above. In this function you should write two lines of code. The first will select the datapoint at the supplied index of the supplied dataset. The second line should plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ClrGPoxrmIF"
   },
   "outputs": [],
   "source": [
    "display_image(x_train, 120) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1PIGwzJs1Q3"
   },
   "source": [
    "# STEP THREE\n",
    "You need to fill in the code for the onehotenencode function above. The function should one hot encode the training and test labels, and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAnqZjTkrmQk"
   },
   "outputs": [],
   "source": [
    "y_train_categorical, y_test_categorical = onehotencode(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KJIMnqGtH3i"
   },
   "source": [
    "# STEP FIVE\n",
    "Now the data is loaded and prepared, the next task is to design a CNN with a single convolutional layer, a single max pooling layer, and two dense layers. \n",
    "\n",
    "* The convolutional layer should have 32 filters, padding should be the 'same' and the kernel size should be 5x5. \n",
    "* The max pooling layer should have a pool size of 2x2 and stride size of 2x2. \n",
    "The dense layers should have 32 and num_classes neurons (units), respectively. \n",
    " * All activation functions should be relu, except for the final layer which should be softmax. \n",
    "* The optimizer should be SGD with a learning rate of 0.001.\n",
    "* Train the network for 10 epochs.\n",
    "\n",
    "\n",
    "Train this network (model.fit()) and evaluate it on the test set (model.evaluate()).\n",
    "\n",
    "Note, each time you train the CNN, you should do so by going to Runtime -> Restart and Run All.\n",
    "\n",
    "What is the accuracy of this CNN on the test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfolUO3jrmfL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 26s 16ms/step - loss: 2.6615 - accuracy: 0.0998\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 2.3044 - accuracy: 0.1012\n",
      "Epoch 3/10\n",
      "1352/1563 [========================>.....] - ETA: 4s - loss: 2.2963 - accuracy: 0.1107"
     ]
    }
   ],
   "source": [
    "model = build_fit_eval_model(x_train, x_test, y_train_categorical, y_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDa1RV-TJCJ9"
   },
   "source": [
    "# STEP SIX\n",
    "Let's modify the CNN to improve performance.\n",
    "\n",
    "Add another another convolutional blocks (Conv2D + Max Pooling) after the first, with the same hyperparameters as the first, but double the number of filters.\n",
    "\n",
    "Note, each time you train the CNN, you should do so by going to Runtime -> Restart and Run All.\n",
    "\n",
    "What is the accuracy of this CNN on the test dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMVHvAgyJOMn"
   },
   "source": [
    "# STEP SEVEN\n",
    "\n",
    "Let's modify the CNN further to improve performance.\n",
    "\n",
    "Add another Dense layer, before the first Dense layer in the network. Give it 64 neurons with relu activation.\n",
    "\n",
    "Note, each time you train the CNN, you should do so by going to Runtime -> Restart and Run All.\n",
    "\n",
    "What is the accuracy of this CNN on the test dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKkprAGHJV_D"
   },
   "source": [
    "# STEP EIGHT\n",
    "\n",
    "Let's try something else. There are many different ways of modifying the network further. For example, we could change the optimizer. SGD is one way of optimizing our neural network, however, more complex optimizers are available. While the theory of them are outside the scope of this unit (deep learning could be unit on its own), they are worth knowing about if you are doing deep learning. Perhaps the most widely used optimizer in deep neural networks is the Adam optimizer, which is an extension of SGD. Thankfully, to use them is easy. Update the optimizer in in the model compile function to use the Adam optimiser with a learning rate of 0.001.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
    "\n",
    "\n",
    "\n",
    "Note, each time you train the CNN, you should do so by going to Runtime -> Restart and Run All.\n",
    "\n",
    "What is the accuracy of this CNN on the test dataset? Report the percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbNzvloQJgKU"
   },
   "source": [
    "# STEP NINE\n",
    "\n",
    "I have provided a function called 'make_predictions'. Use this function, supplying indexes 333 and 1375 of the test set. Ensure that two images are produced alongside their labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pM4MVtuHIkI"
   },
   "source": [
    "The labels map to the class names as follows:\n",
    "* 0 is airplane\n",
    "* 1 is automobile\n",
    "* 2 is bird\n",
    "* 3 is cat \n",
    "* 4 is deer\n",
    "* 5 is dog\n",
    "* 6 is frog\n",
    "* 7 is horse\n",
    "* 8 is ship\n",
    "* 9 is truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFI_JZoErkr8"
   },
   "outputs": [],
   "source": [
    "make_predictions(model, data, indices)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
